# LLM Provider Configuration
# Set to "ollama" (local) or "gemini" (cloud API)
LLM_PROVIDER=gemini

# Gemini API (required if LLM_PROVIDER=gemini)
# Get your key at: https://aistudio.google.com/apikey
GEMINI_API_KEY=AIzaSyDCRX-sGqp9ZyLj37z-jo2UU1Zw36q3XrA
GEMINI_MODEL=gemini-2.0-flash

# Ollama Configuration (used if LLM_PROVIDER=ollama)
OLLAMA_MODEL=llama3.1
