# LLM Provider Configuration
# Set to "ollama" (local) or "gemini" (cloud API)
LLM_PROVIDER=ollama

# Gemini API (required if LLM_PROVIDER=gemini)
# Get your key at: https://aistudio.google.com/apikey
GEMINI_API_KEY=your-api-key-here
GEMINI_MODEL=gemini-2.0-flash

# Ollama Configuration (used if LLM_PROVIDER=ollama)
OLLAMA_MODEL=llama3.1
